# -*- coding: utf-8 -*-
"""house price analysis&prediction linear regression

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/house-price-analysis-prediction-linear-regression-1803a642-0cc3-4272-8c42-241ad06a96e2.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20240807/auto/storage/goog4_request%26X-Goog-Date%3D20240807T002134Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D1956711301d37aea0470a97c948240f1377bc3c003063a480f8ae0e5b627b28d15d3e0b3982d461ffa9ed940257d7622e1af1c2d0d8e6730d8e64a5a4cca037f1a0fc56df72bb15677178e08ed303ef774815ed6e134033cd64b41dad616aee345c3ab27cbc1795bc26e3b6ab81ca8eb09229ecd13b9db5ec5199cfcde813bbe4555ade99791280728fd5c78f9d98823ad1c1410cc8bd50186c3745e49894d4d7edfb40309eaf4365ea67054bf8eac9f7f8b0942faa7a87099a439242a990ea031b86bce9bb842678d2afb0733678c610cef2f45c6590b35e036912d514a037d7061ed7943634e61bc0262a94530d2bfcaaa8914b54335b28744c578a2368382
"""

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES
# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.

import os
import sys
from tempfile import NamedTemporaryFile
from urllib.request import urlopen
from urllib.parse import unquote, urlparse
from urllib.error import HTTPError
from zipfile import ZipFile
import tarfile
import shutil

CHUNK_SIZE = 40960
DATA_SOURCE_MAPPING = 'housedata:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F46927%2F85203%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240807%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240807T002134Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D5fc808ef9295ed49332e6861fd57a8863273c4a0a229aea3694d4165e2bf3098f8bba5ee960bb43627d3c3dbcb16aca5b26a6bb41d2a625bff738bfdd080b977f167563140f5d71cac37ebbeb9ff1e0ee010f243f22d44482fa56d0e0615bf03488e25cda0b26f5cc3955a057a3ef955663dd801a045e2a5bdb8e201c3f399bad32b058b1242b20864e282b5586baac764646470ccb6bdd7bf49c1a97b2fce90474c00812877874e1d8a625c0b9af727c9bd4876606dafc42c9661701149ea4ff4e373fbac84ac942192ad3c7ab5a36b920aef8ae822b0acb0bcd327764098dc6a61e75d5e70b50e86c394275ea0690234c268a99fa2c0599bedec940fb74ae2'

KAGGLE_INPUT_PATH='/kaggle/input'
KAGGLE_WORKING_PATH='/kaggle/working'
KAGGLE_SYMLINK='kaggle'

!umount /kaggle/input/ 2> /dev/null
shutil.rmtree('/kaggle/input', ignore_errors=True)
os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)
os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)

try:
  os.symlink(KAGGLE_INPUT_PATH, os.path.join("..", 'input'), target_is_directory=True)
except FileExistsError:
  pass
try:
  os.symlink(KAGGLE_WORKING_PATH, os.path.join("..", 'working'), target_is_directory=True)
except FileExistsError:
  pass

for data_source_mapping in DATA_SOURCE_MAPPING.split(','):
    directory, download_url_encoded = data_source_mapping.split(':')
    download_url = unquote(download_url_encoded)
    filename = urlparse(download_url).path
    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)
    try:
        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:
            total_length = fileres.headers['content-length']
            print(f'Downloading {directory}, {total_length} bytes compressed')
            dl = 0
            data = fileres.read(CHUNK_SIZE)
            while len(data) > 0:
                dl += len(data)
                tfile.write(data)
                done = int(50 * dl / int(total_length))
                sys.stdout.write(f"\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded")
                sys.stdout.flush()
                data = fileres.read(CHUNK_SIZE)
            if filename.endswith('.zip'):
              with ZipFile(tfile) as zfile:
                zfile.extractall(destination_path)
            else:
              with tarfile.open(tfile.name) as tarfile:
                tarfile.extractall(destination_path)
            print(f'\nDownloaded and uncompressed: {directory}')
    except HTTPError as e:
        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')
        continue
    except OSError as e:
        print(f'Failed to load {download_url} to path {destination_path}')
        continue

print('Data source import complete.')

"""# imports"""

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score
import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))
# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory
# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All"
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

"""# load data"""

df=pd.read_csv("/kaggle/input/housedata/data.csv")
print(df.head())
data=df.drop(columns=['date','street', 'city','statezip', 'country'])

df['date'] = pd.to_datetime(df['date'])

df.tail(5)

"""# analysis"""

col=[]
for i,v in enumerate(df.columns,1):
    col.append({i,v})
print(col)

df.info()
print(df.index)

df.describe()
#statistics function for my data

df.isnull().sum()

print(f"duplicated number --> {df.duplicated().sum()}")

print(f" the highest price {df['price'].max()}")# Highest house price
print(f" Lowest price {df['price'][df.price>0].min()}") #Lowest house price

# Represent distribution Price on a specific day
b=np.arange(stop=2384000,start=235000,step=100000)
sns.histplot(df,x=df['price'][df['date']=='2014-05-02 00:00:00'],kde=True,bins=b)
plt.title('distribution of price in 2014-05-02')

sns.scatterplot(data=df,x='sqft_living',y='price') #Most sqft_living are in between 8000-2000

l=['bedrooms','bathrooms','sqft_living','sqft_lot','floors','view']
for i,v in enumerate(l,1):
    plt.figure(figsize=(3,3))
    plt.subplot(6,1,i)
    sns.lmplot(df,x=v,y='price')

plt.figure(figsize=(20, 10))
sns.countplot(df.head(50),x='city')
plt.title('distribution for first 50 row ')

l=['bedrooms','bathrooms','floors']
plt.figure(figsize=(10,10))
for i,v in enumerate(l,1):
    plt.subplot(3,1,i)
    sns.histplot(df[v],kde=True,palette='plasma')
    plt.title(f'Distribution for {v}')
    plt.xlabel(v)
    plt.ylabel('Frequency')
plt.tight_layout()
# from draw can show :
# Distribution for 3 and 4 bedrooms is the highest and 3 bathrooms and 1,2 floors too

sns.countplot(x="bedrooms",data=df,width=0.1)
plt.title('destribution of bedrooms  ')
plt.show()
# most bedroom distribution is 3

sns.pairplot(df)
# Shows us scatter for each pair columns together

"""# correlation matt"""

corr_matrix=data.corr(method="pearson")
plt.figure(figsize=(10,10))
sns.heatmap(corr_matrix,annot=True,cmap='Blues')
high_corr_feature=corr_matrix.index[abs(corr_matrix['price'])>=0.2].tolist()
high_corr_feature.remove('price')# Remove the target variable from the list
# print(corr_matrix)
print(high_corr_feature)

"""# muild the model"""

y=df['price']
x=df[high_corr_feature]
scaler = StandardScaler()
scaler.fit(x)
# x=scaler.transform(x)
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.012552,random_state=58)
X_train = scaler.fit_transform(x_train)
X_test = scaler.transform(x_test)
print(f"x train examples -->{x_train.shape[0]} from {x.shape[0]}")
print(f"x test examples -->{x_test.shape[0]} from {y.shape[0]}")

reg=LinearRegression()
reg.fit(x_train,y_train)

y_test_pre=reg.predict(x_test)
test_acc=r2_score(y_test,y_test_pre)
test_acc





